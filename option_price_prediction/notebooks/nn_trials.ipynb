{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../data/processed/train.parquet\")\n",
    "train_x, train_y = train.drop(\"y\", axis=1), train[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_parquet(\"../data/processed/test.parquet\")[[\"S\", \"K\", \"T\", \"r\", \"sigma\"]]\n",
    "test_y = pd.read_parquet(\"../data/processed/test.parquet\")[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(train_x.values, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "test_x = torch.tensor(test_x.values, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(train_x, train_y),\n",
    "        batch_size=64,\n",
    "        num_workers=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 5\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.2)\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 3, 80)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model = define_model(trial)\n",
    "    criterion = nn.MSELoss()\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for _ in range(EPOCHS):\n",
    "        model.train()\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(test_x)\n",
    "        test_loss = criterion(y_pred, test_y)\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:16:17,315] A new study created in memory with name: hypertuning nn\n",
      "[I 2024-01-06 18:17:31,651] Trial 0 finished with value: 314.4565734863281 and parameters: {'n_layers': 1, 'dropout_rate': 0.10075036850564095, 'n_units_l0': 61, 'lr': 0.00023626438375531529}. Best is trial 0 with value: 314.4565734863281.\n",
      "[I 2024-01-06 18:18:40,474] Trial 1 finished with value: 178.87303161621094 and parameters: {'n_layers': 1, 'dropout_rate': 0.1599540048628091, 'n_units_l0': 11, 'lr': 0.0029356143638398268}. Best is trial 1 with value: 178.87303161621094.\n",
      "[I 2024-01-06 18:20:41,432] Trial 2 finished with value: 43.995269775390625 and parameters: {'n_layers': 2, 'dropout_rate': 0.1791285572912763, 'n_units_l0': 76, 'n_units_l1': 69, 'lr': 0.009891378437105627}. Best is trial 2 with value: 43.995269775390625.\n",
      "[I 2024-01-06 18:22:12,795] Trial 3 finished with value: 212.5325164794922 and parameters: {'n_layers': 2, 'dropout_rate': 0.11685798703694757, 'n_units_l0': 7, 'n_units_l1': 10, 'lr': 0.0025386047182289506}. Best is trial 2 with value: 43.995269775390625.\n",
      "[I 2024-01-06 18:23:30,525] Trial 4 finished with value: 1222.4808349609375 and parameters: {'n_layers': 1, 'dropout_rate': 0.19161804394682513, 'n_units_l0': 61, 'lr': 0.000109580543858971}. Best is trial 2 with value: 43.995269775390625.\n",
      "[I 2024-01-06 18:24:44,174] Trial 5 finished with value: 2174.7880859375 and parameters: {'n_layers': 1, 'dropout_rate': 0.10042329357964674, 'n_units_l0': 26, 'lr': 0.00013378004354816254}. Best is trial 2 with value: 43.995269775390625.\n",
      "[I 2024-01-06 18:26:01,499] Trial 6 finished with value: 65.32345581054688 and parameters: {'n_layers': 1, 'dropout_rate': 0.13136248690109137, 'n_units_l0': 46, 'lr': 0.0021089266390816245}. Best is trial 2 with value: 43.995269775390625.\n",
      "[I 2024-01-06 18:27:43,572] Trial 7 finished with value: 129.9309844970703 and parameters: {'n_layers': 2, 'dropout_rate': 0.19306257561522094, 'n_units_l0': 10, 'n_units_l1': 65, 'lr': 0.0013860855158967795}. Best is trial 2 with value: 43.995269775390625.\n",
      "[I 2024-01-06 18:29:24,823] Trial 8 finished with value: 55.66338348388672 and parameters: {'n_layers': 3, 'dropout_rate': 0.1777227589366993, 'n_units_l0': 64, 'n_units_l1': 24, 'n_units_l2': 23, 'lr': 0.006847082194743523}. Best is trial 2 with value: 43.995269775390625.\n",
      "[I 2024-01-06 18:30:42,255] Trial 9 finished with value: 108.44841766357422 and parameters: {'n_layers': 2, 'dropout_rate': 0.12097286793042225, 'n_units_l0': 36, 'n_units_l1': 19, 'lr': 0.0001670196280854742}. Best is trial 2 with value: 43.995269775390625.\n",
      "[I 2024-01-06 18:32:45,715] Trial 10 finished with value: 6.591200828552246 and parameters: {'n_layers': 3, 'dropout_rate': 0.1579730550350812, 'n_units_l0': 80, 'n_units_l1': 79, 'n_units_l2': 79, 'lr': 0.0004981149493962182}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:35:03,483] Trial 11 finished with value: 12.519527435302734 and parameters: {'n_layers': 3, 'dropout_rate': 0.15965360754943936, 'n_units_l0': 80, 'n_units_l1': 79, 'n_units_l2': 77, 'lr': 0.00045053240128125065}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:37:19,957] Trial 12 finished with value: 21.268972396850586 and parameters: {'n_layers': 3, 'dropout_rate': 0.15357398111829657, 'n_units_l0': 80, 'n_units_l1': 80, 'n_units_l2': 80, 'lr': 0.000459623320990679}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:38:51,574] Trial 13 finished with value: 12.323006629943848 and parameters: {'n_layers': 3, 'dropout_rate': 0.14123121440784497, 'n_units_l0': 72, 'n_units_l1': 50, 'n_units_l2': 80, 'lr': 0.0005700147960854859}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:40:18,706] Trial 14 finished with value: 18.34779930114746 and parameters: {'n_layers': 3, 'dropout_rate': 0.13914707224009115, 'n_units_l0': 69, 'n_units_l1': 48, 'n_units_l2': 58, 'lr': 0.0005784086314481432}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:42:03,529] Trial 15 finished with value: 20.45061683654785 and parameters: {'n_layers': 3, 'dropout_rate': 0.14304316865458752, 'n_units_l0': 50, 'n_units_l1': 45, 'n_units_l2': 54, 'lr': 0.0009940619515740646}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:43:32,892] Trial 16 finished with value: 627.9933471679688 and parameters: {'n_layers': 3, 'dropout_rate': 0.17289590174232589, 'n_units_l0': 55, 'n_units_l1': 55, 'n_units_l2': 4, 'lr': 0.00033335044909689135}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:45:02,934] Trial 17 finished with value: 42.8079719543457 and parameters: {'n_layers': 3, 'dropout_rate': 0.16956151094599936, 'n_units_l0': 71, 'n_units_l1': 33, 'n_units_l2': 64, 'lr': 0.0009349316036361101}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:46:27,562] Trial 18 finished with value: 32.7957649230957 and parameters: {'n_layers': 2, 'dropout_rate': 0.12954116937164611, 'n_units_l0': 35, 'n_units_l1': 62, 'lr': 0.000742334802045245}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:47:53,749] Trial 19 finished with value: 13.995641708374023 and parameters: {'n_layers': 3, 'dropout_rate': 0.14633411987124553, 'n_units_l0': 70, 'n_units_l1': 36, 'n_units_l2': 35, 'lr': 0.000288469592320999}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:49:26,240] Trial 20 finished with value: 36.45794677734375 and parameters: {'n_layers': 3, 'dropout_rate': 0.16356415239291636, 'n_units_l0': 55, 'n_units_l1': 57, 'n_units_l2': 69, 'lr': 0.0015104173799829004}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:51:38,958] Trial 21 finished with value: 9.226789474487305 and parameters: {'n_layers': 3, 'dropout_rate': 0.15402818774898655, 'n_units_l0': 78, 'n_units_l1': 80, 'n_units_l2': 80, 'lr': 0.0005164794423010889}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:54:04,489] Trial 22 finished with value: 16.048818588256836 and parameters: {'n_layers': 3, 'dropout_rate': 0.15480956590958345, 'n_units_l0': 74, 'n_units_l1': 73, 'n_units_l2': 79, 'lr': 0.0005488137153596664}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:55:57,221] Trial 23 finished with value: 10.886114120483398 and parameters: {'n_layers': 3, 'dropout_rate': 0.13516487262598, 'n_units_l0': 66, 'n_units_l1': 75, 'n_units_l2': 69, 'lr': 0.0001994458114837645}. Best is trial 10 with value: 6.591200828552246.\n",
      "[I 2024-01-06 18:57:31,651] Trial 24 finished with value: 18.96834945678711 and parameters: {'n_layers': 2, 'dropout_rate': 0.13116129522139963, 'n_units_l0': 63, 'n_units_l1': 73, 'lr': 0.000180084862298876}. Best is trial 10 with value: 6.591200828552246.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"hypertuning nn\", direction=\"minimize\")\n",
    "\n",
    "study.optimize(objective, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  6.591200828552246\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    dropout_rate: 0.1579730550350812\n",
      "    n_units_l0: 80\n",
      "    n_units_l1: 79\n",
      "    n_units_l2: 79\n",
      "    lr: 0.0004981149493962182\n"
     ]
    }
   ],
   "source": [
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
